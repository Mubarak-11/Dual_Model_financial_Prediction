{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c0099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:29:19,374 | INFO | Utilizing CPU since GPU doesn't exit here: cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import logging, time, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import torch.optim.lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, confusion_matrix, classification_report, f1_score\n",
    "from preprocessing import preprocess\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "logger.info(f\"Utilizing CPU since GPU doesn't exit here: {device} \\n\")\n",
    "\n",
    "class prepfortorch(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "\n",
    "        #since x is a dense numpy array\n",
    "        if hasattr(x, \"toarray\"):   \n",
    "            X = x.toarray()\n",
    "        else:\n",
    "            X = x\n",
    "            \n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        y = y.to_numpy().astype(np.float32).reshape(-1) # so its 1-D\n",
    "\n",
    "        self.X = torch.from_numpy(X) #create tensors from numpy arrays\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34ac59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classmodel(nn.Module):\n",
    "    def __init__(self, num_feat):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential( #set up the container\n",
    "            nn.Linear(num_feat, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1) #BCEwithLogitsLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "def train_time(df, model, n_factors = 30, n_epochs = 20, batch_size = 50, device = \"cpu\", pos_weights = None, val_ds = None):\n",
    "\n",
    "        #lets start off with AdamW optimizer and l2 regularization (weight decay)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr = 0.001, weight_decay= 1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode = 'min',\n",
    "            factor= 0.5,\n",
    "            patience= 2,\n",
    "            min_lr = 1e-6\n",
    "        )\n",
    "\n",
    "        criteron = nn.BCEWithLogitsLoss(pos_weight= pos_weights)\n",
    "        \n",
    "        #train/val Dataloader method\n",
    "        data_loader = DataLoader(df, batch_size= 512, shuffle= True, drop_last=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=512, shuffle=False, drop_last= True)\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        best_model_state = None #initiliazation\n",
    "        no_improve_epochs = 0\n",
    "        epoch_loss = []\n",
    "\n",
    "        history = [] #to save everything(mode, weights and parameters)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for batchx, batchy in data_loader:\n",
    "                batchx = batchx.to(device)\n",
    "                batchy = batchy.to(device).float().unsqueeze(1) \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                prediction = model(batchx)\n",
    "\n",
    "                loss = criteron(prediction, batchy)\n",
    "                bs = batchx.size(0) #batch size to calculate total loss \n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss += loss.item() * bs #scale by batch size\n",
    "                total_samples += bs\n",
    "\n",
    "                #validation phase\n",
    "            \n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            val_sample = 0\n",
    "\n",
    "            with torch.no_grad():   #no more gradient calculation\n",
    "                for batchx, batchy in val_loader:\n",
    "                    batchx = batchx.to(device)\n",
    "                    batchy = batchy.to(device).float().unsqueeze(1)\n",
    "\n",
    "                    #make the prediction\n",
    "                    prediction = model(batchx)\n",
    "\n",
    "                    loss = criteron(prediction, batchy)\n",
    "                    vs = batchx.size(0)\n",
    "\n",
    "                    total_val_loss +=loss.item() * vs\n",
    "                    val_sample += vs\n",
    "                \n",
    "            \n",
    "            avg_train_loss = total_train_loss / total_samples\n",
    "            avg_val_loss = total_val_loss / val_sample\n",
    "\n",
    "            epoch_loss.append(avg_val_loss)\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "            if (epoch + 1)%1 ==0:\n",
    "                logging.info((f\"Epoch {epoch+1} / {n_epochs} train Loss: {avg_train_loss:.4f}, valid loss: {avg_val_loss:.4f}\"))\n",
    "            \n",
    "            #print metrics from validate function\n",
    "            val_metrics = validate(val_ds, model, device, batch_size)\n",
    "            \n",
    "            logging.info(f\"val PR-AUC: {val_metrics['pr_auc']:.5f}, val ROC-AUC: {val_metrics['roc_score']:.5f}, F1: {val_metrics['f1'].max():.5f} , Tau: {val_metrics['tau']:.5f} \")\n",
    "            \n",
    "            #save now\n",
    "            history.append({ \"epoch\": epoch+1,\n",
    "                            \"train_loss\": avg_train_loss,\n",
    "                            \"val_loss\": avg_val_loss,\n",
    "                            })\n",
    "            \n",
    "            #early stopping check\n",
    "            if avg_val_loss < best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                no_improve_epochs = 0\n",
    "                best_model_state = model.state_dict() #save the best model weights\n",
    "            \n",
    "            else:\n",
    "                no_improve_epochs += 1\n",
    "            \n",
    "            if no_improve_epochs >= 5:\n",
    "                logging.info(f\"Stopping early at epoch {epoch+1} -No improvement for 5 epoch\")\n",
    "                break\n",
    "            \n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "        model.cpu() #move model back to the cpu\n",
    "\n",
    "        plt.plot(epoch_loss)\n",
    "        plt.title(\"Validation\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        return model, best_model_state, {\"history\": history}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff91d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(valid_set, model, device, batch_size):\n",
    "\n",
    "    #enter evaluation mode - important for batch normalization/dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    valid_loader = DataLoader(valid_set, batch_size= batch_size, shuffle= False)\n",
    "\n",
    "    all_p, all_y = [], [] #empty lists to hold\n",
    "    for batchx, batchy in valid_loader:\n",
    "        batchx = batchx.to(device)\n",
    "        batchy = batchy.to(device).float().unsqueeze(1)\n",
    "\n",
    "        #make prediction\n",
    "        predict = model(batchx)\n",
    "\n",
    "        probs = torch.sigmoid(predict) # or like this we did for the titanic  pred_labels = (pred >= 0.5).long().squeeze() #convert into class lables (0 -> not survived, 1-> survived)\n",
    "\n",
    "        all_p.append(probs.cpu()); all_y.append(batchy.cpu())\n",
    "    \n",
    "    y = torch.cat(all_y).numpy()\n",
    "    p = torch.cat(all_p).numpy()\n",
    "\n",
    "    pr_auc = average_precision_score(y, p)\n",
    "    roc_score = roc_auc_score(y, p)\n",
    "    prec, rec, thr = precision_recall_curve(y, p)\n",
    "    \n",
    "    f1 = 2*prec*rec / (prec + rec + 1e-12)\n",
    "    best = f1.argmax()\n",
    "    tau = thr[max (0, best-1)]\n",
    "    \n",
    "    return  pr_auc,  roc_score,  f1,  float(tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73e1e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(run_dir, model, best_state):\n",
    "    \"\"\" Save for model depolyment\"\"\"\n",
    "\n",
    "    Path(run_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #save cpu tensors\n",
    "    best_state_cpu = {k: v.cpu() for k, v in best_state.items()}\n",
    "    model_cpu = model.to(\"cpu\")\n",
    "\n",
    "    #Now save best model and weights\n",
    "    torch.save(best_state, f\"{run_dir}/ model_state.pt\")\n",
    "\n",
    "    #save entire model (no need to redefine class)\n",
    "    torch.save(model, f\"{run_dir}.model_full.pt\" )\n",
    "\n",
    "    print(f\"âœ… Model saved to {run_dir} at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "868486f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_set, model, tau, batch_size):\n",
    "    \n",
    "    #lets really evaluate the model using the test set now!!\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size= batch_size, shuffle= False)\n",
    "    all_p, all_y = [], [] #empty lists to hold\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batchx, batchy in test_loader:\n",
    "            batchx = batchx.to(device)\n",
    "            batchy = batchy.to(device)\n",
    "\n",
    "            predict = model(batchx)\n",
    "\n",
    "            proba = torch.sigmoid(predict) #convert from logits to probabalities \n",
    "\n",
    "            all_p.append(proba.cpu()); all_y.append(batchy.cpu())\n",
    "        \n",
    "        y = torch.cat(all_y).numpy() #concatatenate the tensors into numpy\n",
    "        p = torch.cat(all_p).numpy()\n",
    "        \n",
    "        pr_curve = average_precision_score(y,p)\n",
    "        roc_auc = roc_auc_score(y, p)\n",
    "\n",
    "        prec, rec, thr = precision_recall_curve(y, p)\n",
    "        \n",
    "        #tau from validation\n",
    "        tau = float(tau)\n",
    "        y_hat = (p >= tau).astype(int)\n",
    "\n",
    "        #now calculate classification report/confusion matrix from fixed set\n",
    "        cm = confusion_matrix(y,y_hat, labels=[0,1])\n",
    "        report = classification_report(\n",
    "            y, y_hat,\n",
    "            labels=[0,1],\n",
    "            target_names=[\"not_fraud\", \"fraud\"],\n",
    "            digits=4,\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"precision_recall_curve: {pr_curve}\")\n",
    "        logger.info(f\"roc_auc score: {roc_auc}\")\n",
    "        logger.info(f\"Confusion Matrix: \\n{cm}\")\n",
    "        logger.info(f\"classification_report: \\n{report}\")\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08423552",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess() got an unexpected keyword argument 'task'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m#now really evaluate using test set\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m#base_model.load_state_dict(torch.load(r\"C:\\Users\\mubarak.derie\\OneDrive - Accenture\\Documents\\Python\\2025_projects\\torch_proj#1_classify\\artificats\\paysim_classify_model_2025-08-13_08-00-46\\ model_state.pt\", map_location=\"cpu\")) #Load the model weights\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m#evaluate(test_ds, base_model, val_tau, batch_size=512)\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m==\u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m df = df1.sample(n=\u001b[32m100000\u001b[39m, random_state= \u001b[32m42\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#logger.info(df.head())\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m x, y, preprocessor = \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclassification\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#split into train+val and test (60% , 20% and 20%)\u001b[39;00m\n\u001b[32m     14\u001b[39m x_temp, x_test, y_temp, y_test = train_test_split(x, y, test_size=\u001b[32m0.2\u001b[39m, stratify=y)\n",
      "\u001b[31mTypeError\u001b[39m: preprocess() got an unexpected keyword argument 'task'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #main method to do everything\n",
    "    df1 = pd.read_parquet(r\"paysim_data_pt.parquet\") #loading 6 million\n",
    "\n",
    "    #lets take a sample of 50-100k for now\n",
    "    df = df1.sample(n=100000, random_state= 42)\n",
    "\n",
    "    #logger.info(df.head())\n",
    "\n",
    "    #\n",
    "    x, y, preprocessor = preprocess(df, task= 'classification')\n",
    "\n",
    "    #split into train+val and test (60% , 20% and 20%)\n",
    "    x_temp, x_test, y_temp, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    #Now split into train and val \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_temp,y_temp, test_size=0.25, stratify=y_temp, random_state = 42)\n",
    "\n",
    "\n",
    "    #apply fit/transform to train set and only tranform on test set\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    x_train_pp = pipeline.fit_transform(x_train).astype(np.float32)\n",
    "    x_val_pp = pipeline.transform(x_val).astype(np.float32)\n",
    "    x_test_pp = pipeline.transform(x_test).astype(np.float32)\n",
    "\n",
    "    #logger.info(f\"{x_train_pp.shape}, {x_test_pp.shape}\")\n",
    "\n",
    "    train_ds = prepfortorch(x_train_pp, y_train)\n",
    "    val_ds = prepfortorch(x_val_pp, y_val)\n",
    "    test_ds = prepfortorch(x_test_pp, y_test)\n",
    "    \n",
    "    #to help with the class imbalance\n",
    "    pos_weights = torch.tensor([\n",
    "        (y_temp == 0).sum() / (y_temp==1).sum() \n",
    "    ], dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "    #Model training time\n",
    "    num_feat = x_train_pp.shape[1] #compress features to number of columns\n",
    "    base_model = classmodel(num_feat)\n",
    "    \n",
    "    #model, best_model_state, logs = train_time(train_ds, base_model, n_factors=30, n_epochs = 25, batch_size= 512, device=\"cpu\", pos_weights= pos_weights, val_ds = val_ds)\n",
    "\n",
    "    #Now save the model to this folder\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_dir = os.path.join(\"artificats\", f\"paysim_classify_model_{timestamp}\")\n",
    "    #save_model(run_dir, model, best_model_state)\n",
    "    \n",
    "    #get tau from validation:\n",
    "    val_pr_auc, val_roc_auc, val_f1, val_tau = validate(val_ds, base_model, device, batch_size=512)\n",
    "\n",
    "    #now really evaluate using test set\n",
    "    #base_model.load_state_dict(torch.load(r\"C:\\Users\\mubarak.derie\\OneDrive - Accenture\\Documents\\Python\\2025_projects\\torch_proj#1_classify\\artificats\\paysim_classify_model_2025-08-13_08-00-46\\ model_state.pt\", map_location=\"cpu\")) #Load the model weights\n",
    "\n",
    "    #evaluate(test_ds, base_model, val_tau, batch_size=512)\n",
    "    \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
